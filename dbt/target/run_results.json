{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.10.15", "generated_at": "2025-11-16T18:10:37.588563Z", "invocation_id": "3503fca0-a639-4a22-bf25-1cda9d9c81df", "invocation_started_at": "2025-11-16T18:10:35.372106Z", "env": {}}, "results": [{"status": "error", "timing": [{"name": "compile", "started_at": "2025-11-16T18:10:36.679381Z", "completed_at": "2025-11-16T18:10:36.726895Z"}, {"name": "execute", "started_at": "2025-11-16T18:10:36.727809Z", "completed_at": "2025-11-16T18:10:36.795822Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.12632322311401367, "adapter_response": {}, "message": "Runtime Error in model stg_customers (models\\staging\\stg_customers.sql)\n  Binder Error: Referenced column \"customer_name\" not found in FROM clause!\n  Candidate bindings: \"customer_id\", \"company_name\", \"contract_start_date\", \"license_utilization\", \"industry\"\n  \n  LINE 7:     customer_name,\n              ^", "failures": null, "unique_id": "model.cybersec_health.stg_customers", "compiled": true, "compiled_code": "select\n    customer_id,\n    customer_name,\n    industry,\n    company_size,\n    contract_start_date::date as contract_start_date,\n    contract_end_date::date as contract_end_date,\n    monthly_recurring_revenue::decimal(10,2) as mrr,\n    account_manager\nfrom read_csv_auto('../data/raw/customers.csv')", "relation_name": "\"cybersec_health_dbt\".\"main\".\"stg_customers\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-16T18:10:36.685407Z", "completed_at": "2025-11-16T18:10:36.744573Z"}, {"name": "execute", "started_at": "2025-11-16T18:10:36.749990Z", "completed_at": "2025-11-16T18:10:36.895587Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.21726632118225098, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.cybersec_health.stg_security_incidents", "compiled": true, "compiled_code": "select\n    \"customer_id\",\n    \"Timestamp\"::timestamp as incident_timestamp,\n    \"Source IP Address\" as source_ip,\n    \"Destination IP Address\" as dest_ip,\n    \"Protocol\",\n    \"Attack Type\" as attack_type,\n    \"Severity Level\" as severity_level,\n    \"Action Taken\" as action_taken,\n    \"Malware Indicators\" as malware_indicators,\n    \"Anomaly Scores\"::float as anomaly_score,\n    \"Alerts/Warnings\" as alerts_warnings,\n    \"Log Source\" as log_source,\n    \"Network Segment\" as network_segment,\n    \"Geo-location Data\" as geo_location,\n    \n    -- Derived fields\n    case \n        when \"Severity Level\" = 'Critical' then 4\n        when \"Severity Level\" = 'High' then 3\n        when \"Severity Level\" = 'Medium' then 2\n        when \"Severity Level\" = 'Low' then 1\n        else 0\n    end as severity_score,\n    \n    case \n        when \"Action Taken\" = 'Blocked' then 'Prevented'\n        when \"Action Taken\" = 'Logged' then 'Detected'\n        when \"Action Taken\" = 'Ignored' then 'Ignored'\n        else 'Unknown'\n    end as response_category,\n    \n    case \n        when \"Malware Indicators\" = 'IoC Detected' then true\n        else false\n    end as has_malware_indicators,\n    \n    case \n        when \"Alerts/Warnings\" = 'Alert Triggered' then true\n        else false\n    end as alert_triggered,\n    \n    -- Threat intelligence enrichment\n    case \n        when \"Source IP Address\" like '10.%' or \"Source IP Address\" like '192.168.%' or \"Source IP Address\" like '172.%' then 'Internal'\n        else 'External'\n    end as ip_classification,\n    \n    -- Geographic risk assessment\n    case \n        when \"Geo-location Data\" like '%China%' or \"Geo-location Data\" like '%Russia%' or \"Geo-location Data\" like '%North Korea%' then 'High Risk Geography'\n        when \"Geo-location Data\" like '%US%' or \"Geo-location Data\" like '%UK%' or \"Geo-location Data\" like '%Canada%' then 'Low Risk Geography'\n        else 'Medium Risk Geography'\n    end as geo_risk_level,\n    \n    -- Port analysis\n    \"Source Port\"::int as source_port,\n    \"Destination Port\"::int as dest_port,\n    case \n        when \"Destination Port\"::int in (22, 23, 3389, 5900) then 'Remote Access'\n        when \"Destination Port\"::int in (80, 443, 8080, 8443) then 'Web Services'\n        when \"Destination Port\"::int in (21, 22, 25, 53, 110, 143) then 'Standard Services'\n        when \"Destination Port\"::int > 1024 then 'High Port'\n        else 'System Port'\n    end as port_category,\n    \n    -- Attack sophistication\n    case \n        when \"Attack Signature\" = 'Known Pattern A' and \"Malware Indicators\" = 'IoC Detected' then 'Advanced'\n        when \"Attack Signature\" = 'Known Pattern B' then 'Intermediate'\n        else 'Basic'\n    end as attack_sophistication\n    \nfrom read_csv_auto('../data/raw/security_incidents.csv')", "relation_name": "\"cybersec_health_dbt\".\"main\".\"stg_security_incidents\"", "batch_results": null}, {"status": "skipped", "timing": [], "thread_id": "Thread-4 (worker)", "execution_time": 0, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.cybersec_health.customer_health_scores", "compiled": false, "compiled_code": null, "relation_name": "\"cybersec_health_dbt\".\"main\".\"customer_health_scores\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-16T18:10:36.915559Z", "completed_at": "2025-11-16T18:10:36.922314Z"}, {"name": "execute", "started_at": "2025-11-16T18:10:36.940480Z", "completed_at": "2025-11-16T18:10:37.188174Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.28578948974609375, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.cybersec_health.security_incident_analytics", "compiled": true, "compiled_code": "with incident_metrics as (\n    select\n        customer_id,\n        count(*) as total_incidents,\n        count(case when severity_level = 'Critical' then 1 end) as critical_incidents,\n        count(case when severity_level = 'High' then 1 end) as high_incidents,\n        count(case when severity_level = 'Medium' then 1 end) as medium_incidents,\n        count(case when severity_level = 'Low' then 1 end) as low_incidents,\n        \n        -- Attack type distribution\n        count(case when attack_type = 'Malware' then 1 end) as malware_incidents,\n        count(case when attack_type = 'DDoS' then 1 end) as ddos_incidents,\n        count(case when attack_type = 'Intrusion' then 1 end) as intrusion_incidents,\n        \n        -- Response effectiveness\n        count(case when response_category = 'Prevented' then 1 end) as prevented_incidents,\n        count(case when response_category = 'Detected' then 1 end) as detected_incidents,\n        count(case when response_category = 'Ignored' then 1 end) as ignored_incidents,\n        \n        -- Malware and alert metrics\n        count(case when has_malware_indicators then 1 end) as incidents_with_malware,\n        count(case when alert_triggered then 1 end) as incidents_with_alerts,\n        \n        -- Severity scoring\n        avg(severity_score) as avg_severity_score,\n        max(severity_score) as max_severity_score,\n        avg(anomaly_score) as avg_anomaly_score,\n        max(anomaly_score) as max_anomaly_score,\n        \n        -- Time-based metrics\n        min(incident_timestamp) as first_incident_date,\n        max(incident_timestamp) as latest_incident_date,\n        count(case when incident_timestamp >= current_date - interval '30 days' then 1 end) as incidents_last_30_days,\n        count(case when incident_timestamp >= current_date - interval '7 days' then 1 end) as incidents_last_7_days\n        \n    from \"cybersec_health_dbt\".\"main\".\"stg_security_incidents\"\n    group by customer_id\n),\n\nrisk_scoring as (\n    select\n        *,\n        -- Calculate risk scores\n        case \n            when critical_incidents > 0 then 'Critical'\n            when high_incidents >= 3 or (high_incidents >= 1 and incidents_last_7_days >= 5) then 'High'\n            when medium_incidents >= 5 or incidents_last_30_days >= 10 then 'Medium'\n            else 'Low'\n        end as security_risk_level,\n        \n        -- Prevention effectiveness ratio\n        case \n            when total_incidents > 0 then \n                round((prevented_incidents::float / total_incidents::float) * 100, 2)\n            else 0\n        end as prevention_rate_pct,\n        \n        -- Alert coverage ratio\n        case \n            when total_incidents > 0 then \n                round((incidents_with_alerts::float / total_incidents::float) * 100, 2)\n            else 0\n        end as alert_coverage_pct\n        \n    from incident_metrics\n)\n\nselect\n    customer_id,\n    total_incidents,\n    critical_incidents,\n    high_incidents,\n    medium_incidents,\n    low_incidents,\n    malware_incidents,\n    ddos_incidents,\n    intrusion_incidents,\n    prevented_incidents,\n    detected_incidents,\n    ignored_incidents,\n    incidents_with_malware,\n    incidents_with_alerts,\n    round(avg_severity_score, 2) as avg_severity_score,\n    max_severity_score,\n    round(avg_anomaly_score, 2) as avg_anomaly_score,\n    round(max_anomaly_score, 2) as max_anomaly_score,\n    first_incident_date,\n    latest_incident_date,\n    incidents_last_30_days,\n    incidents_last_7_days,\n    security_risk_level,\n    prevention_rate_pct,\n    alert_coverage_pct,\n    \n    -- Additional derived metrics\n    case \n        when prevention_rate_pct >= 80 then 'Excellent'\n        when prevention_rate_pct >= 60 then 'Good'\n        when prevention_rate_pct >= 40 then 'Fair'\n        else 'Poor'\n    end as prevention_effectiveness,\n    \n    case \n        when alert_coverage_pct >= 90 then 'Excellent'\n        when alert_coverage_pct >= 70 then 'Good'\n        when alert_coverage_pct >= 50 then 'Fair'\n        else 'Poor'\n    end as alert_coverage_rating\n\nfrom risk_scoring\norder by \n    case security_risk_level\n        when 'Critical' then 1\n        when 'High' then 2\n        when 'Medium' then 3\n        when 'Low' then 4\n    end,\n    total_incidents desc", "relation_name": "\"cybersec_health_dbt\".\"main\".\"security_incident_analytics\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-16T18:10:36.912547Z", "completed_at": "2025-11-16T18:10:36.923519Z"}, {"name": "execute", "started_at": "2025-11-16T18:10:36.943512Z", "completed_at": "2025-11-16T18:10:37.190325Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.28784775733947754, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.cybersec_health.security_clustering_analysis", "compiled": true, "compiled_code": "with customer_features as (\n    select\n        customer_id,\n        count(*) as incident_count,\n        avg(severity_score) as avg_severity,\n        avg(anomaly_score) as avg_anomaly,\n        count(distinct attack_type) as attack_variety,\n        count(distinct source_ip) as unique_ips,\n        count(distinct network_segment) as segments_affected,\n        count(case when response_category = 'Prevented' then 1 end)::float / count(*) as prevention_rate,\n        \n        -- Time patterns\n        stddev(extract(hour from incident_timestamp)) as hour_variance,\n        count(case when extract(hour from incident_timestamp) between 0 and 6 then 1 end) as night_incidents,\n        count(case when extract(dow from incident_timestamp) in (0,6) then 1 end) as weekend_incidents,\n        \n        -- Attack sophistication\n        count(case when attack_sophistication = 'Advanced' then 1 end) as advanced_attacks,\n        count(case when geo_risk_level = 'High Risk Geography' then 1 end) as high_risk_geo_attacks\n        \n    from \"cybersec_health_dbt\".\"main\".\"stg_security_incidents\"\n    group by customer_id\n),\n\nnormalized_features as (\n    select\n        customer_id,\n        -- Normalize features for clustering (0-1 scale)\n        (incident_count - min(incident_count) over()) / nullif(max(incident_count) over() - min(incident_count) over(), 0) as norm_incident_count,\n        (avg_severity - min(avg_severity) over()) / nullif(max(avg_severity) over() - min(avg_severity) over(), 0) as norm_avg_severity,\n        (avg_anomaly - min(avg_anomaly) over()) / nullif(max(avg_anomaly) over() - min(avg_anomaly) over(), 0) as norm_avg_anomaly,\n        (attack_variety - min(attack_variety) over()) / nullif(max(attack_variety) over() - min(attack_variety) over(), 0) as norm_attack_variety,\n        prevention_rate as norm_prevention_rate,\n        (advanced_attacks - min(advanced_attacks) over()) / nullif(max(advanced_attacks) over() - min(advanced_attacks) over(), 0) as norm_advanced_attacks,\n        \n        -- Original values for interpretation\n        incident_count,\n        avg_severity,\n        avg_anomaly,\n        attack_variety,\n        prevention_rate,\n        advanced_attacks,\n        high_risk_geo_attacks\n    from customer_features\n),\n\ncustomer_clusters as (\n    select\n        customer_id,\n        incident_count,\n        round(avg_severity, 2) as avg_severity,\n        round(avg_anomaly, 2) as avg_anomaly,\n        attack_variety,\n        round(prevention_rate * 100, 2) as prevention_rate_pct,\n        advanced_attacks,\n        high_risk_geo_attacks,\n        \n        -- Simple clustering based on key metrics\n        case \n            when norm_incident_count >= 0.8 and norm_avg_severity >= 0.7 then 'High Volume High Severity'\n            when norm_incident_count >= 0.8 and norm_avg_severity < 0.7 then 'High Volume Low Severity'\n            when norm_incident_count < 0.8 and norm_avg_severity >= 0.7 then 'Low Volume High Severity'\n            when norm_advanced_attacks >= 0.5 then 'Advanced Threat Targets'\n            when norm_prevention_rate <= 0.3 then 'Poor Defense'\n            when norm_prevention_rate >= 0.8 then 'Strong Defense'\n            else 'Standard Profile'\n        end as customer_cluster,\n        \n        -- Risk score calculation\n        round(\n            (norm_incident_count * 0.3 + \n             norm_avg_severity * 0.3 + \n             norm_avg_anomaly * 0.2 + \n             norm_advanced_attacks * 0.2) * 100, 2\n        ) as composite_risk_score\n        \n    from normalized_features\n)\n\nselect\n    customer_cluster,\n    count(*) as customers_in_cluster,\n    round(avg(incident_count), 1) as avg_incidents,\n    round(avg(avg_severity), 2) as cluster_avg_severity,\n    round(avg(avg_anomaly), 2) as cluster_avg_anomaly,\n    round(avg(prevention_rate_pct), 2) as cluster_avg_prevention_rate,\n    round(avg(composite_risk_score), 2) as cluster_avg_risk_score,\n    \n    -- Cluster characteristics\n    case \n        when customer_cluster = 'High Volume High Severity' then 'Critical - Immediate attention required'\n        when customer_cluster = 'Advanced Threat Targets' then 'High - Enhanced monitoring needed'\n        when customer_cluster = 'Poor Defense' then 'High - Security improvements needed'\n        when customer_cluster = 'Low Volume High Severity' then 'Medium - Monitor for escalation'\n        when customer_cluster = 'Strong Defense' then 'Low - Maintain current posture'\n        else 'Medium - Standard monitoring'\n    end as cluster_priority,\n    \n    -- Recommended actions\n    case \n        when customer_cluster = 'High Volume High Severity' then 'Deploy additional security controls, incident response team engagement'\n        when customer_cluster = 'Advanced Threat Targets' then 'Threat hunting, advanced detection rules, security assessment'\n        when customer_cluster = 'Poor Defense' then 'Security architecture review, prevention capability enhancement'\n        when customer_cluster = 'Low Volume High Severity' then 'Root cause analysis, targeted security measures'\n        when customer_cluster = 'Strong Defense' then 'Continue current practices, periodic review'\n        else 'Regular monitoring and standard security practices'\n    end as recommended_actions\n\nfrom customer_clusters\ngroup by customer_cluster\norder by cluster_avg_risk_score desc", "relation_name": "\"cybersec_health_dbt\".\"main\".\"security_clustering_analysis\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-16T18:10:36.908882Z", "completed_at": "2025-11-16T18:10:36.922314Z"}, {"name": "execute", "started_at": "2025-11-16T18:10:36.923519Z", "completed_at": "2025-11-16T18:10:37.261014Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.35889506340026855, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.cybersec_health.security_attack_patterns", "compiled": true, "compiled_code": "with incident_sequences as (\n    select\n        customer_id,\n        incident_timestamp,\n        attack_type,\n        severity_level,\n        source_ip,\n        network_segment,\n        lag(attack_type) over (partition by customer_id order by incident_timestamp) as prev_attack_type,\n        lag(incident_timestamp) over (partition by customer_id order by incident_timestamp) as prev_timestamp,\n        lead(attack_type) over (partition by customer_id order by incident_timestamp) as next_attack_type,\n        lead(incident_timestamp) over (partition by customer_id order by incident_timestamp) as next_timestamp\n    from \"cybersec_health_dbt\".\"main\".\"stg_security_incidents\"\n),\n\nattack_chains as (\n    select\n        customer_id,\n        incident_timestamp,\n        attack_type,\n        severity_level,\n        source_ip,\n        network_segment,\n        prev_attack_type,\n        next_attack_type,\n        case \n            when prev_timestamp is not null then \n                extract(epoch from (incident_timestamp - prev_timestamp)) / 60.0\n            else null\n        end as minutes_since_prev,\n        case \n            when next_timestamp is not null then \n                extract(epoch from (next_timestamp - incident_timestamp)) / 60.0\n            else null\n        end as minutes_to_next,\n        \n        -- Identify potential attack chains\n        case \n            when prev_attack_type is not null and \n                 extract(epoch from (incident_timestamp - prev_timestamp)) / 60.0 <= 60\n            then concat(prev_attack_type, ' -> ', attack_type)\n            else null\n        end as attack_sequence\n    from incident_sequences\n),\n\npattern_analysis as (\n    select\n        customer_id,\n        attack_sequence,\n        count(*) as sequence_count,\n        avg(minutes_since_prev) as avg_time_between,\n        min(incident_timestamp) as first_occurrence,\n        max(incident_timestamp) as last_occurrence\n    from attack_chains\n    where attack_sequence is not null\n    group by customer_id, attack_sequence\n),\n\ncustomer_patterns as (\n    select\n        customer_id,\n        count(distinct attack_type) as unique_attack_types,\n        count(distinct source_ip) as unique_source_ips,\n        count(distinct network_segment) as segments_affected,\n        \n        -- Time-based patterns\n        extract(hour from incident_timestamp) as attack_hour,\n        extract(dow from incident_timestamp) as attack_dow,\n        \n        -- Escalation patterns\n        case \n            when severity_level = 'Low' and next_attack_type is not null and minutes_to_next <= 30 then 'Potential Escalation'\n            when prev_attack_type = 'Intrusion' and attack_type = 'Malware' and minutes_since_prev <= 60 then 'Intrusion to Malware'\n            when prev_attack_type = 'DDoS' and attack_type = 'Intrusion' and minutes_since_prev <= 120 then 'DDoS to Intrusion'\n            else 'Isolated'\n        end as pattern_type\n        \n    from attack_chains\n    group by customer_id, incident_timestamp, attack_type, severity_level, next_attack_type, prev_attack_type, minutes_to_next, minutes_since_prev\n)\n\nselect\n    customer_id,\n    pattern_type,\n    count(*) as pattern_occurrences,\n    avg(unique_attack_types) as avg_attack_variety,\n    avg(unique_source_ips) as avg_ip_variety,\n    avg(segments_affected) as avg_segments_affected,\n    \n    -- Time patterns\n    mode() within group (order by attack_hour) as most_common_hour,\n    mode() within group (order by attack_dow) as most_common_day,\n    \n    -- Risk assessment\n    case \n        when pattern_type in ('Potential Escalation', 'Intrusion to Malware') then 'High Risk'\n        when pattern_type = 'DDoS to Intrusion' then 'Medium Risk'\n        else 'Low Risk'\n    end as pattern_risk_level\n\nfrom customer_patterns\ngroup by customer_id, pattern_type\norder by customer_id, pattern_occurrences desc", "relation_name": "\"cybersec_health_dbt\".\"main\".\"security_attack_patterns\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-16T18:10:36.919477Z", "completed_at": "2025-11-16T18:10:36.939511Z"}, {"name": "execute", "started_at": "2025-11-16T18:10:36.947156Z", "completed_at": "2025-11-16T18:10:37.304624Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.3926229476928711, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.cybersec_health.security_incidents_daily", "compiled": true, "compiled_code": "with daily_incidents as (\n    select\n        date_trunc('day', incident_timestamp) as incident_date,\n        customer_id,\n        attack_type,\n        severity_level,\n        response_category,\n        count(*) as incident_count,\n        avg(severity_score) as avg_severity_score,\n        avg(anomaly_score) as avg_anomaly_score,\n        count(case when has_malware_indicators then 1 end) as malware_count,\n        count(case when alert_triggered then 1 end) as alert_count\n    from \"cybersec_health_dbt\".\"main\".\"stg_security_incidents\"\n    group by 1, 2, 3, 4, 5\n),\n\ndaily_summary as (\n    select\n        incident_date,\n        customer_id,\n        sum(incident_count) as total_daily_incidents,\n        sum(case when severity_level = 'Critical' then incident_count else 0 end) as critical_count,\n        sum(case when severity_level = 'High' then incident_count else 0 end) as high_count,\n        sum(case when severity_level = 'Medium' then incident_count else 0 end) as medium_count,\n        sum(case when severity_level = 'Low' then incident_count else 0 end) as low_count,\n        \n        sum(case when attack_type = 'Malware' then incident_count else 0 end) as malware_incidents,\n        sum(case when attack_type = 'DDoS' then incident_count else 0 end) as ddos_incidents,\n        sum(case when attack_type = 'Intrusion' then incident_count else 0 end) as intrusion_incidents,\n        \n        sum(case when response_category = 'Prevented' then incident_count else 0 end) as prevented_count,\n        sum(case when response_category = 'Detected' then incident_count else 0 end) as detected_count,\n        sum(case when response_category = 'Ignored' then incident_count else 0 end) as ignored_count,\n        \n        sum(malware_count) as total_malware_indicators,\n        sum(alert_count) as total_alerts,\n        \n        avg(avg_severity_score) as daily_avg_severity,\n        avg(avg_anomaly_score) as daily_avg_anomaly\n        \n    from daily_incidents\n    group by 1, 2\n)\n\nselect\n    incident_date,\n    customer_id,\n    total_daily_incidents,\n    critical_count,\n    high_count,\n    medium_count,\n    low_count,\n    malware_incidents,\n    ddos_incidents,\n    intrusion_incidents,\n    prevented_count,\n    detected_count,\n    ignored_count,\n    total_malware_indicators,\n    total_alerts,\n    round(daily_avg_severity, 2) as daily_avg_severity,\n    round(daily_avg_anomaly, 2) as daily_avg_anomaly,\n    \n    -- Calculate prevention rate for the day\n    case \n        when total_daily_incidents > 0 then \n            round((prevented_count::float / total_daily_incidents::float) * 100, 2)\n        else 0\n    end as daily_prevention_rate_pct,\n    \n    -- Risk level for the day\n    case \n        when critical_count > 0 then 'Critical'\n        when high_count >= 2 then 'High'\n        when high_count >= 1 or medium_count >= 3 then 'Medium'\n        else 'Low'\n    end as daily_risk_level,\n    \n    -- Moving averages (7-day window)\n    avg(total_daily_incidents) over (\n        partition by customer_id \n        order by incident_date \n        rows between 6 preceding and current row\n    ) as incidents_7day_avg,\n    \n    avg(daily_avg_severity) over (\n        partition by customer_id \n        order by incident_date \n        rows between 6 preceding and current row\n    ) as severity_7day_avg\n\nfrom daily_summary\norder by customer_id, incident_date desc", "relation_name": "\"cybersec_health_dbt\".\"main\".\"security_incidents_daily\"", "batch_results": null}, {"status": "error", "timing": [{"name": "compile", "started_at": "2025-11-16T18:10:37.266694Z", "completed_at": "2025-11-16T18:10:37.274102Z"}, {"name": "execute", "started_at": "2025-11-16T18:10:37.275100Z", "completed_at": "2025-11-16T18:10:37.419490Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.15981078147888184, "adapter_response": {}, "message": "Runtime Error in model security_network_analysis (models\\marts\\security_network_analysis.sql)\n  Binder Error: Referenced column \"medium_pct\" not found in FROM clause!\n  Candidate bindings: \"medium_count\", \"udp_incidents\", \"malware_count\", \"intrusion_count\", \"ddos_count\"\n  \n  LINE 103:         when (critical_pct + high_pct + medium_pct) > 50 then 'Medium'\n                                                    ^", "failures": null, "unique_id": "model.cybersec_health.security_network_analysis", "compiled": true, "compiled_code": "with network_incidents as (\n    select\n        network_segment,\n        attack_type,\n        severity_level,\n        protocol,\n        log_source,\n        count(*) as incident_count,\n        count(distinct customer_id) as affected_customers,\n        avg(severity_score) as avg_severity_score,\n        avg(anomaly_score) as avg_anomaly_score,\n        count(case when has_malware_indicators then 1 end) as malware_incidents,\n        count(case when alert_triggered then 1 end) as alert_incidents,\n        count(case when response_category = 'Prevented' then 1 end) as prevented_incidents\n    from \"cybersec_health_dbt\".\"main\".\"stg_security_incidents\"\n    group by 1, 2, 3, 4, 5\n),\n\nsegment_summary as (\n    select\n        network_segment,\n        sum(incident_count) as total_incidents,\n        sum(affected_customers) as total_affected_customers,\n        \n        -- Attack type breakdown\n        sum(case when attack_type = 'Malware' then incident_count else 0 end) as malware_count,\n        sum(case when attack_type = 'DDoS' then incident_count else 0 end) as ddos_count,\n        sum(case when attack_type = 'Intrusion' then incident_count else 0 end) as intrusion_count,\n        \n        -- Severity breakdown\n        sum(case when severity_level = 'Critical' then incident_count else 0 end) as critical_count,\n        sum(case when severity_level = 'High' then incident_count else 0 end) as high_count,\n        sum(case when severity_level = 'Medium' then incident_count else 0 end) as medium_count,\n        sum(case when severity_level = 'Low' then incident_count else 0 end) as low_count,\n        \n        -- Protocol breakdown\n        sum(case when protocol = 'TCP' then incident_count else 0 end) as tcp_incidents,\n        sum(case when protocol = 'UDP' then incident_count else 0 end) as udp_incidents,\n        sum(case when protocol = 'ICMP' then incident_count else 0 end) as icmp_incidents,\n        \n        -- Source breakdown\n        sum(case when log_source = 'Firewall' then incident_count else 0 end) as firewall_incidents,\n        sum(case when log_source = 'Server' then incident_count else 0 end) as server_incidents,\n        \n        sum(malware_incidents) as total_malware_indicators,\n        sum(alert_incidents) as total_alerts,\n        sum(prevented_incidents) as total_prevented,\n        \n        avg(avg_severity_score) as segment_avg_severity,\n        avg(avg_anomaly_score) as segment_avg_anomaly\n        \n    from network_incidents\n    group by 1\n)\n\nselect\n    network_segment,\n    total_incidents,\n    total_affected_customers,\n    malware_count,\n    ddos_count,\n    intrusion_count,\n    critical_count,\n    high_count,\n    medium_count,\n    low_count,\n    tcp_incidents,\n    udp_incidents,\n    icmp_incidents,\n    firewall_incidents,\n    server_incidents,\n    total_malware_indicators,\n    total_alerts,\n    total_prevented,\n    round(segment_avg_severity, 2) as segment_avg_severity,\n    round(segment_avg_anomaly, 2) as segment_avg_anomaly,\n    \n    -- Calculate percentages\n    round((malware_count::float / total_incidents::float) * 100, 2) as malware_pct,\n    round((ddos_count::float / total_incidents::float) * 100, 2) as ddos_pct,\n    round((intrusion_count::float / total_incidents::float) * 100, 2) as intrusion_pct,\n    \n    round((critical_count::float / total_incidents::float) * 100, 2) as critical_pct,\n    round((high_count::float / total_incidents::float) * 100, 2) as high_pct,\n    \n    round((total_prevented::float / total_incidents::float) * 100, 2) as prevention_rate_pct,\n    round((total_alerts::float / total_incidents::float) * 100, 2) as alert_rate_pct,\n    \n    -- Risk assessment per segment\n    case \n        when critical_count > 0 and critical_pct > 20 then 'Critical'\n        when high_count > 0 and (critical_pct + high_pct) > 30 then 'High'\n        when (critical_pct + high_pct + medium_pct) > 50 then 'Medium'\n        else 'Low'\n    end as segment_risk_level,\n    \n    -- Most common attack type\n    case \n        when malware_count >= ddos_count and malware_count >= intrusion_count then 'Malware'\n        when ddos_count >= intrusion_count then 'DDoS'\n        else 'Intrusion'\n    end as primary_attack_type,\n    \n    -- Most common protocol\n    case \n        when tcp_incidents >= udp_incidents and tcp_incidents >= icmp_incidents then 'TCP'\n        when udp_incidents >= icmp_incidents then 'UDP'\n        else 'ICMP'\n    end as primary_protocol\n\nfrom segment_summary\norder by total_incidents desc, segment_avg_severity desc", "relation_name": "\"cybersec_health_dbt\".\"main\".\"security_network_analysis\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-16T18:10:37.203110Z", "completed_at": "2025-11-16T18:10:37.216276Z"}, {"name": "execute", "started_at": "2025-11-16T18:10:37.217360Z", "completed_at": "2025-11-16T18:10:37.476532Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.2766687870025635, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.cybersec_health.security_ip_analysis", "compiled": true, "compiled_code": "with ip_incidents as (\n    select\n        source_ip,\n        count(*) as total_incidents,\n        count(distinct customer_id) as customers_affected,\n        count(distinct geo_location) as locations_count,\n        avg(severity_score) as avg_severity,\n        max(severity_score) as max_severity,\n        count(case when attack_type = 'Malware' then 1 end) as malware_attacks,\n        count(case when attack_type = 'DDoS' then 1 end) as ddos_attacks,\n        count(case when attack_type = 'Intrusion' then 1 end) as intrusion_attacks,\n        count(case when response_category = 'Prevented' then 1 end) as prevented_count,\n        min(incident_timestamp) as first_seen,\n        max(incident_timestamp) as last_seen,\n        count(case when incident_timestamp >= current_date - interval '7 days' then 1 end) as recent_activity\n    from \"cybersec_health_dbt\".\"main\".\"stg_security_incidents\"\n    group by source_ip\n),\n\nip_reputation as (\n    select\n        *,\n        case \n            when customers_affected >= 5 and avg_severity >= 3 then 'High Risk'\n            when customers_affected >= 3 or avg_severity >= 2.5 then 'Medium Risk'\n            when total_incidents >= 10 then 'Suspicious'\n            else 'Low Risk'\n        end as threat_level,\n        \n        case \n            when malware_attacks >= ddos_attacks and malware_attacks >= intrusion_attacks then 'Malware'\n            when ddos_attacks >= intrusion_attacks then 'DDoS'\n            else 'Intrusion'\n        end as primary_attack_type,\n        \n        round((prevented_count::float / total_incidents::float) * 100, 2) as prevention_rate_pct\n    from ip_incidents\n)\n\nselect\n    source_ip,\n    total_incidents,\n    customers_affected,\n    locations_count,\n    round(avg_severity, 2) as avg_severity,\n    max_severity,\n    malware_attacks,\n    ddos_attacks,\n    intrusion_attacks,\n    prevented_count,\n    first_seen,\n    last_seen,\n    recent_activity,\n    threat_level,\n    primary_attack_type,\n    prevention_rate_pct,\n    \n    -- Calculate persistence score\n    case \n        when recent_activity > 0 and total_incidents >= 5 then 'Persistent'\n        when recent_activity > 0 then 'Active'\n        when last_seen >= current_date - interval '30 days' then 'Recent'\n        else 'Historical'\n    end as activity_status\n    \nfrom ip_reputation\norder by \n    case threat_level\n        when 'High Risk' then 1\n        when 'Medium Risk' then 2\n        when 'Suspicious' then 3\n        else 4\n    end,\n    total_incidents desc", "relation_name": "\"cybersec_health_dbt\".\"main\".\"security_ip_analysis\"", "batch_results": null}, {"status": "error", "timing": [{"name": "compile", "started_at": "2025-11-16T18:10:37.208323Z", "completed_at": "2025-11-16T18:10:37.221568Z"}, {"name": "execute", "started_at": "2025-11-16T18:10:37.222571Z", "completed_at": "2025-11-16T18:10:37.499793Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.307877779006958, "adapter_response": {}, "message": "Runtime Error in model security_kpi_dashboard (models\\marts\\security_kpi_dashboard.sql)\n  Binder Error: Referenced column \"alert_triggered\" not found in FROM clause!\n  Candidate bindings: \"alerted_incidents\", \"total_incidents\", \"total_customers\"\n  \n  LINE 39:         avg(case when alert_triggered then 15 else 45 end) as mttr_minutes,\n                                 ^", "failures": null, "unique_id": "model.cybersec_health.security_kpi_dashboard", "compiled": true, "compiled_code": "with current_metrics as (\n    select\n        count(distinct customer_id) as total_customers,\n        count(*) as total_incidents,\n        count(case when severity_level = 'Critical' then 1 end) as critical_incidents,\n        count(case when severity_level = 'High' then 1 end) as high_incidents,\n        count(case when response_category = 'Prevented' then 1 end) as prevented_incidents,\n        count(case when alert_triggered then 1 end) as alerted_incidents,\n        count(case when incident_timestamp >= current_date - interval '24 hours' then 1 end) as incidents_24h,\n        count(case when incident_timestamp >= current_date - interval '7 days' then 1 end) as incidents_7d,\n        count(case when incident_timestamp >= current_date - interval '30 days' then 1 end) as incidents_30d,\n        avg(anomaly_score) as avg_anomaly_score\n    from \"cybersec_health_dbt\".\"main\".\"stg_security_incidents\"\n),\n\nprevious_period as (\n    select\n        count(*) as prev_total_incidents,\n        count(case when severity_level = 'Critical' then 1 end) as prev_critical_incidents,\n        count(case when response_category = 'Prevented' then 1 end) as prev_prevented_incidents\n    from \"cybersec_health_dbt\".\"main\".\"stg_security_incidents\"\n    where incident_timestamp >= current_date - interval '60 days'\n    and incident_timestamp < current_date - interval '30 days'\n),\n\nsla_metrics as (\n    select\n        -- Mean Time to Detection (simulated)\n        avg(case when alert_triggered then 15 else 45 end) as mttr_minutes,\n        \n        -- Prevention rate\n        round((prevented_incidents::float / total_incidents::float) * 100, 2) as prevention_rate,\n        \n        -- Alert coverage\n        round((alerted_incidents::float / total_incidents::float) * 100, 2) as alert_coverage,\n        \n        -- Critical incident rate\n        round((critical_incidents::float / total_incidents::float) * 100, 2) as critical_rate\n        \n    from current_metrics\n),\n\ntrend_analysis as (\n    select\n        cm.*,\n        pp.*,\n        sm.*,\n        \n        -- Calculate trends\n        case \n            when pp.prev_total_incidents > 0 then\n                round(((cm.incidents_30d - pp.prev_total_incidents)::float / pp.prev_total_incidents::float) * 100, 2)\n            else 0\n        end as incident_trend_pct,\n        \n        case \n            when pp.prev_critical_incidents > 0 then\n                round(((cm.critical_incidents - pp.prev_critical_incidents)::float / pp.prev_critical_incidents::float) * 100, 2)\n            else 0\n        end as critical_trend_pct,\n        \n        case \n            when pp.prev_prevented_incidents > 0 then\n                round(((cm.prevented_incidents - pp.prev_prevented_incidents)::float / pp.prev_prevented_incidents::float) * 100, 2)\n            else 0\n        end as prevention_trend_pct\n        \n    from current_metrics cm\n    cross join previous_period pp\n    cross join sla_metrics sm\n)\n\nselect\n    -- Current state\n    total_customers,\n    total_incidents,\n    critical_incidents,\n    high_incidents,\n    incidents_24h,\n    incidents_7d,\n    incidents_30d,\n    \n    -- Performance metrics\n    prevention_rate,\n    alert_coverage,\n    critical_rate,\n    round(avg_anomaly_score, 2) as avg_anomaly_score,\n    round(mttr_minutes, 1) as mttr_minutes,\n    \n    -- Trends\n    incident_trend_pct,\n    critical_trend_pct,\n    prevention_trend_pct,\n    \n    -- Status indicators\n    case \n        when critical_rate > 20 then 'Critical'\n        when critical_rate > 10 then 'High'\n        when critical_rate > 5 then 'Medium'\n        else 'Good'\n    end as security_posture,\n    \n    case \n        when prevention_rate >= 80 then 'Excellent'\n        when prevention_rate >= 60 then 'Good'\n        when prevention_rate >= 40 then 'Fair'\n        else 'Poor'\n    end as prevention_status,\n    \n    case \n        when alert_coverage >= 90 then 'Excellent'\n        when alert_coverage >= 70 then 'Good'\n        when alert_coverage >= 50 then 'Fair'\n        else 'Poor'\n    end as detection_status,\n    \n    case \n        when incident_trend_pct <= -10 then 'Improving'\n        when incident_trend_pct <= 10 then 'Stable'\n        when incident_trend_pct <= 25 then 'Concerning'\n        else 'Critical'\n    end as trend_status,\n    \n    current_timestamp as last_updated\n\nfrom trend_analysis", "relation_name": "\"cybersec_health_dbt\".\"main\".\"security_kpi_dashboard\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-11-16T18:10:37.308601Z", "completed_at": "2025-11-16T18:10:37.311288Z"}, {"name": "execute", "started_at": "2025-11-16T18:10:37.312548Z", "completed_at": "2025-11-16T18:10:37.534378Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.22783112525939941, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.cybersec_health.security_predictive_analytics", "compiled": true, "compiled_code": "with customer_history as (\n    select\n        customer_id,\n        extract(hour from incident_timestamp) as incident_hour,\n        extract(dow from incident_timestamp) as incident_dow,\n        attack_type,\n        severity_score,\n        anomaly_score,\n        network_segment,\n        \n        -- Time-based features\n        row_number() over (partition by customer_id order by incident_timestamp desc) as recency_rank,\n        count(*) over (partition by customer_id) as total_incidents,\n        avg(severity_score) over (partition by customer_id) as avg_customer_severity,\n        \n        -- Sequence features\n        lag(attack_type) over (partition by customer_id order by incident_timestamp) as prev_attack,\n        lag(severity_score) over (partition by customer_id order by incident_timestamp) as prev_severity,\n        \n        -- Time gaps\n        case \n            when lag(incident_timestamp) over (partition by customer_id order by incident_timestamp) is not null then\n                extract(epoch from (incident_timestamp - lag(incident_timestamp) over (partition by customer_id order by incident_timestamp))) / 3600.0\n            else null\n        end as hours_since_last\n        \n    from \"cybersec_health_dbt\".\"main\".\"stg_security_incidents\"\n),\n\nrisk_patterns as (\n    select\n        customer_id,\n        \n        -- Behavioral patterns\n        mode() within group (order by incident_hour) as peak_attack_hour,\n        mode() within group (order by incident_dow) as peak_attack_day,\n        mode() within group (order by attack_type) as most_common_attack,\n        \n        -- Risk indicators\n        avg(severity_score) as avg_severity,\n        max(severity_score) as max_severity,\n        avg(anomaly_score) as avg_anomaly,\n        stddev(anomaly_score) as anomaly_variance,\n        \n        -- Frequency patterns\n        count(*) as incident_count,\n        avg(hours_since_last) as avg_time_between_incidents,\n        min(hours_since_last) as min_time_between_incidents,\n        \n        -- Escalation patterns\n        count(case when prev_severity < severity_score then 1 end) as escalation_count,\n        count(case when prev_attack != attack_type then 1 end) as attack_type_changes,\n        \n        -- Recent activity\n        count(case when recency_rank <= 5 then 1 end) as recent_incidents,\n        avg(case when recency_rank <= 5 then severity_score end) as recent_avg_severity\n        \n    from customer_history\n    group by customer_id\n),\n\npredictive_scores as (\n    select\n        *,\n        \n        -- Next attack likelihood (0-100)\n        least(100, greatest(0, \n            case \n                when avg_time_between_incidents <= 24 then 85\n                when avg_time_between_incidents <= 72 then 65\n                when avg_time_between_incidents <= 168 then 45\n                else 25\n            end +\n            case when recent_avg_severity >= 3 then 15 else 0 end +\n            case when escalation_count > 0 then 10 else 0 end +\n            case when anomaly_variance > 20 then 10 else 0 end\n        )) as next_attack_probability,\n        \n        -- Severity prediction\n        case \n            when recent_avg_severity >= 3.5 then 'Critical'\n            when recent_avg_severity >= 2.5 then 'High'\n            when recent_avg_severity >= 1.5 then 'Medium'\n            else 'Low'\n        end as predicted_next_severity,\n        \n        -- Time to next incident (hours)\n        case \n            when avg_time_between_incidents is not null then\n                round(avg_time_between_incidents * \n                    case \n                        when recent_incidents >= 3 then 0.7  -- More frequent if recent activity\n                        when escalation_count > 0 then 0.8\n                        else 1.0\n                    end, 1)\n            else null\n        end as predicted_hours_to_next,\n        \n        -- Risk classification\n        case \n            when next_attack_probability >= 80 then 'Imminent'\n            when next_attack_probability >= 60 then 'High Risk'\n            when next_attack_probability >= 40 then 'Medium Risk'\n            else 'Low Risk'\n        end as risk_classification\n        \n    from risk_patterns\n)\n\nselect\n    customer_id,\n    peak_attack_hour,\n    peak_attack_day,\n    most_common_attack,\n    round(avg_severity, 2) as avg_severity,\n    max_severity,\n    round(avg_anomaly, 2) as avg_anomaly,\n    round(anomaly_variance, 2) as anomaly_variance,\n    incident_count,\n    round(avg_time_between_incidents, 1) as avg_time_between_incidents,\n    round(min_time_between_incidents, 1) as min_time_between_incidents,\n    escalation_count,\n    attack_type_changes,\n    recent_incidents,\n    round(recent_avg_severity, 2) as recent_avg_severity,\n    next_attack_probability,\n    predicted_next_severity,\n    predicted_hours_to_next,\n    risk_classification,\n    \n    -- Recommended actions\n    case \n        when risk_classification = 'Imminent' then 'Immediate monitoring and preventive measures'\n        when risk_classification = 'High Risk' then 'Enhanced monitoring and security controls'\n        when risk_classification = 'Medium Risk' then 'Regular monitoring and review'\n        else 'Standard monitoring'\n    end as recommended_action,\n    \n    current_timestamp as prediction_timestamp\n\nfrom predictive_scores\norder by next_attack_probability desc, recent_avg_severity desc", "relation_name": "\"cybersec_health_dbt\".\"main\".\"security_predictive_analytics\"", "batch_results": null}, {"status": "error", "timing": [{"name": "compile", "started_at": "2025-11-16T18:10:37.434810Z", "completed_at": "2025-11-16T18:10:37.447256Z"}, {"name": "execute", "started_at": "2025-11-16T18:10:37.447256Z", "completed_at": "2025-11-16T18:10:37.573652Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.14544415473937988, "adapter_response": {}, "message": "Runtime Error in model security_seasonal_trends (models\\marts\\security_seasonal_trends.sql)\n  Binder Error: Could not ORDER BY column \"CASE  WHEN ((analysis_type = 'Summary')) THEN (0) ELSE 1 END\": add the expression/function to every SELECT, or move the UNION into a FROM clause.", "failures": null, "unique_id": "model.cybersec_health.security_seasonal_trends", "compiled": true, "compiled_code": "with time_series_data as (\n    select\n        date_trunc('week', incident_timestamp) as week_start,\n        date_trunc('month', incident_timestamp) as month_start,\n        extract(hour from incident_timestamp) as hour_of_day,\n        extract(dow from incident_timestamp) as day_of_week,\n        extract(month from incident_timestamp) as month_of_year,\n        extract(quarter from incident_timestamp) as quarter,\n        \n        attack_type,\n        severity_level,\n        customer_id,\n        \n        count(*) as incident_count,\n        avg(severity_score) as avg_severity,\n        avg(anomaly_score) as avg_anomaly\n        \n    from \"cybersec_health_dbt\".\"main\".\"stg_security_incidents\"\n    group by 1, 2, 3, 4, 5, 6, 7, 8, 9\n),\n\nhourly_patterns as (\n    select\n        hour_of_day,\n        sum(incident_count) as total_incidents,\n        avg(avg_severity) as avg_hourly_severity,\n        count(distinct customer_id) as customers_affected,\n        \n        -- Attack type distribution by hour\n        sum(case when attack_type = 'Malware' then incident_count else 0 end) as malware_incidents,\n        sum(case when attack_type = 'DDoS' then incident_count else 0 end) as ddos_incidents,\n        sum(case when attack_type = 'Intrusion' then incident_count else 0 end) as intrusion_incidents\n        \n    from time_series_data\n    group by hour_of_day\n),\n\ndaily_patterns as (\n    select\n        case day_of_week\n            when 0 then 'Sunday'\n            when 1 then 'Monday'\n            when 2 then 'Tuesday'\n            when 3 then 'Wednesday'\n            when 4 then 'Thursday'\n            when 5 then 'Friday'\n            when 6 then 'Saturday'\n        end as day_name,\n        day_of_week,\n        sum(incident_count) as total_incidents,\n        avg(avg_severity) as avg_daily_severity,\n        count(distinct customer_id) as customers_affected\n        \n    from time_series_data\n    group by day_of_week\n),\n\nmonthly_patterns as (\n    select\n        case month_of_year\n            when 1 then 'January' when 2 then 'February' when 3 then 'March'\n            when 4 then 'April' when 5 then 'May' when 6 then 'June'\n            when 7 then 'July' when 8 then 'August' when 9 then 'September'\n            when 10 then 'October' when 11 then 'November' when 12 then 'December'\n        end as month_name,\n        month_of_year,\n        sum(incident_count) as total_incidents,\n        avg(avg_severity) as avg_monthly_severity,\n        count(distinct customer_id) as customers_affected\n        \n    from time_series_data\n    group by month_of_year\n),\n\nquarterly_trends as (\n    select\n        quarter,\n        sum(incident_count) as total_incidents,\n        avg(avg_severity) as avg_quarterly_severity,\n        count(distinct customer_id) as customers_affected,\n        \n        -- Calculate quarter-over-quarter growth\n        lag(sum(incident_count)) over (order by quarter) as prev_quarter_incidents,\n        case \n            when lag(sum(incident_count)) over (order by quarter) > 0 then\n                round(((sum(incident_count) - lag(sum(incident_count)) over (order by quarter))::float / \n                       lag(sum(incident_count)) over (order by quarter)::float) * 100, 2)\n            else null\n        end as qoq_growth_pct\n        \n    from time_series_data\n    group by quarter\n),\n\npeak_analysis as (\n    select\n        'Hourly' as time_dimension,\n        (select hour_of_day from hourly_patterns order by total_incidents desc limit 1) as peak_time,\n        (select total_incidents from hourly_patterns order by total_incidents desc limit 1) as peak_incidents,\n        'Peak attack hour' as description\n    \n    union all\n    \n    select\n        'Daily' as time_dimension,\n        (select day_name from daily_patterns order by total_incidents desc limit 1) as peak_time,\n        (select total_incidents from daily_patterns order by total_incidents desc limit 1) as peak_incidents,\n        'Peak attack day' as description\n    \n    union all\n    \n    select\n        'Monthly' as time_dimension,\n        (select month_name from monthly_patterns order by total_incidents desc limit 1) as peak_time,\n        (select total_incidents from monthly_patterns order by total_incidents desc limit 1) as peak_incidents,\n        'Peak attack month' as description\n)\n\n-- Final output combining all patterns\nselect\n    'Summary' as analysis_type,\n    json_object(\n        'peak_hour', (select peak_time from peak_analysis where time_dimension = 'Hourly'),\n        'peak_day', (select peak_time from peak_analysis where time_dimension = 'Daily'),\n        'peak_month', (select peak_time from peak_analysis where time_dimension = 'Monthly'),\n        'total_incidents', (select sum(total_incidents) from hourly_patterns),\n        'avg_severity', (select round(avg(avg_hourly_severity), 2) from hourly_patterns)\n    ) as trend_summary,\n    current_timestamp as analysis_timestamp\n\nunion all\n\nselect\n    'Hourly Distribution' as analysis_type,\n    json_object(\n        'hour', hour_of_day,\n        'incidents', total_incidents,\n        'severity', round(avg_hourly_severity, 2),\n        'customers', customers_affected\n    ) as trend_summary,\n    current_timestamp as analysis_timestamp\nfrom hourly_patterns\norder by \n    case when analysis_type = 'Summary' then 0 else 1 end,\n    trend_summary", "relation_name": "\"cybersec_health_dbt\".\"main\".\"security_seasonal_trends\"", "batch_results": null}], "elapsed_time": 1.0416810512542725, "args": {"profiles_dir": ".", "log_format_file": "debug", "empty": false, "log_level_file": "debug", "require_explicit_package_overrides_for_builtin_materializations": true, "show_all_deprecations": false, "source_freshness_run_project_hooks": true, "print": true, "cache_selected_only": false, "printer_width": 80, "indirect_selection": "eager", "use_colors": true, "log_file_max_bytes": 10485760, "use_colors_file": true, "write_json": true, "require_nested_cumulative_type_params": false, "select": [], "vars": {}, "static_parser": true, "populate_cache": true, "strict_mode": false, "exclude": [], "version_check": true, "quiet": false, "send_anonymous_usage_stats": true, "require_resource_names_without_spaces": true, "show_resource_report": false, "require_generic_test_arguments_property": true, "skip_nodes_if_on_run_start_fails": false, "warn_error_options": {"error": [], "warn": [], "silence": []}, "state_modified_compare_vars": false, "introspect": true, "state_modified_compare_more_unrendered_values": false, "project_dir": "c:\\Users\\pearc\\cyberproject\\cybersec-customer-health-pipeline\\dbt", "partial_parse": true, "favor_state": false, "log_level": "info", "require_all_warnings_handled_by_warn_error": false, "validate_macro_args": false, "macro_debugging": false, "use_fast_test_edges": false, "require_yaml_configuration_for_mf_time_spines": false, "upload_to_artifacts_ingest_api": false, "which": "run", "log_path": "c:\\Users\\pearc\\cyberproject\\cybersec-customer-health-pipeline\\dbt\\logs", "partial_parse_file_diff": true, "invocation_command": "dbt ", "require_batched_execution_for_custom_microbatch_strategy": false, "log_format": "default", "defer": false}}